\BOOKMARK [1][-]{section.1}{Introduction}{}% 1
\BOOKMARK [1][-]{section.2}{Data Preprocessing}{}% 2
\BOOKMARK [2][-]{subsection.2.1}{Mel Scale}{section.2}% 3
\BOOKMARK [2][-]{subsection.2.2}{Standardization}{section.2}% 4
\BOOKMARK [2][-]{subsection.2.3}{Removing Redundancy}{section.2}% 5
\BOOKMARK [2][-]{subsection.2.4}{Smoothing}{section.2}% 6
\BOOKMARK [2][-]{subsection.2.5}{Data Expansion}{section.2}% 7
\BOOKMARK [2][-]{subsection.2.6}{Centralization}{section.2}% 8
\BOOKMARK [2][-]{subsection.2.7}{Other Approaches}{section.2}% 9
\BOOKMARK [1][-]{section.3}{Models}{}% 10
\BOOKMARK [2][-]{subsection.3.1}{Models in Comparison}{section.3}% 11
\BOOKMARK [2][-]{subsection.3.2}{Other Models We Explored}{section.3}% 12
\BOOKMARK [3][-]{subsubsection.3.2.1}{Attention-based Recurrent Neural Networks}{subsection.3.2}% 13
\BOOKMARK [3][-]{subsubsection.3.2.2}{Temporal CNN + Attention-based LSTM}{subsection.3.2}% 14
\BOOKMARK [1][-]{section.4}{Experiments}{}% 15
\BOOKMARK [2][-]{subsection.4.1}{Hyperparameters}{section.4}% 16
\BOOKMARK [2][-]{subsection.4.2}{Experiments result}{section.4}% 17
\BOOKMARK [1][-]{section.5}{Conclusion}{}% 18
\BOOKMARK [2][-]{subsection.5.1}{Time consumption}{section.5}% 19
\BOOKMARK [2][-]{subsection.5.2}{Accuracy}{section.5}% 20
\BOOKMARK [2][-]{subsection.5.3}{Analysis}{section.5}% 21
\BOOKMARK [1][-]{section.6}{References}{}% 22
